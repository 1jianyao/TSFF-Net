# YOLOv5 ğŸš€ by Ultralytics, AGPL-3.0 license
"""
Dataloaders and dataset utils
"""

import contextlib
import glob
import hashlib
import json
import math
import os
import random
import shutil
import time
from itertools import repeat
from multiprocessing.pool import Pool, ThreadPool
from pathlib import Path
from threading import Thread
from urllib.parse import urlparse

import numpy as np
import psutil
import torch
import torch.nn.functional as F
import torchvision
import yaml
from PIL import ExifTags, Image, ImageOps
from torch.utils.data import DataLoader, Dataset, dataloader, distributed
from tqdm import tqdm

from utils.augmentations import (Albumentations, augment_hsv, copy_paste,
                                  letterbox, mixup, random_perspective)
from utils.general import (DATASETS_DIR, LOGGER, NUM_THREADS, TQDM_BAR_FORMAT, check_dataset, check_requirements,
                           check_yaml, clean_str, cv2, is_colab, is_kaggle, segments2boxes, unzip_file, xyn2xy,
                           xywh2xyxy, xywhn2xyxy, xyxy2xywhn)
from utils.torch_utils import torch_distributed_zero_first

# Parameters
HELP_URL = 'See https://docs.ultralytics.com/yolov5/tutorials/train_custom_data'
IMG_FORMATS = 'bmp', 'dng', 'jpeg', 'jpg', 'mpo', 'png', 'tif', 'tiff', 'webp', 'pfm'  # include image suffixes
VID_FORMATS = 'asf', 'avi', 'gif', 'm4v', 'mkv', 'mov', 'mp4', 'mpeg', 'mpg', 'ts', 'wmv'  # include video suffixes
LOCAL_RANK = int(os.getenv('LOCAL_RANK', -1))  # https://pytorch.org/docs/stable/elastic/run.html
RANK = int(os.getenv('RANK', -1))
PIN_MEMORY = str(os.getenv('PIN_MEMORY', True)).lower() == 'true'  # global pin_memory for dataloaders
BAR_FORMAT = '{l_bar}{bar:10}{r_bar}{bar:-10b}'  # tqdm bar format
# Get orientation exif tag
for orientation in ExifTags.TAGS.keys():
    if ExifTags.TAGS[orientation] == 'Orientation':
        break


def get_hash(paths):
    # Returns a single hash value of a list of paths (files or dirs)
    size = sum(os.path.getsize(p) for p in paths if os.path.exists(p))  # sizes
    h = hashlib.sha256(str(size).encode())  # hash sizes
    h.update(''.join(paths).encode())  # hash paths
    return h.hexdigest()  # return hash


def exif_size(img):
    # Returns exif-corrected PIL size
    s = img.size  # (width, height)
    with contextlib.suppress(Exception):
        rotation = dict(img._getexif().items())[orientation]
        if rotation in [6, 8]:  # rotation 270 or 90
            s = (s[1], s[0])
    return s


def exif_transpose(image):
    """
    Transpose a PIL image accordingly if it has an EXIF Orientation tag.
    Inplace version of https://github.com/python-pillow/Pillow/blob/master/src/PIL/ImageOps.py exif_transpose()

    :param image: The image to transpose.
    :return: An image.
    """
    exif = image.getexif()
    orientation = exif.get(0x0112, 1)  # default 1
    if orientation > 1:
        method = {
            2: Image.FLIP_LEFT_RIGHT,
            3: Image.ROTATE_180,
            4: Image.FLIP_TOP_BOTTOM,
            5: Image.TRANSPOSE,
            6: Image.ROTATE_270,
            7: Image.TRANSVERSE,
            8: Image.ROTATE_90}.get(orientation)
        if method is not None:
            image = image.transpose(method)
            del exif[0x0112]
            image.info['exif'] = exif.tobytes()
    return image


def seed_worker(worker_id):
    # Set dataloader worker seed https://pytorch.org/docs/stable/notes/randomness.html#dataloader
    worker_seed = torch.initial_seed() % 2 ** 32
    np.random.seed(worker_seed)
    random.seed(worker_seed)


def create_dataloader(path,
                      path2,
                      imgsz,
                      batch_size,
                      stride,
                      single_cls=False,
                      hyp=None,
                      augment=False,
                      cache=False,
                      pad=0.0,
                      rect=False,
                      rank=-1,
                      workers=8,
                      image_weights=False,
                      quad=False,
                      prefix='',
                      prefix2='',
                      shuffle=False,
                      seed=0):
    """ å‚æ•°ï¼š
        path: å›¾ç‰‡æ•°æ®åŠ è½½è·¯å¾„ D:\yolo5-5\yolov5\paper_data\images
        imgsz: train/testå›¾ç‰‡å°ºå¯¸ï¼ˆæ•°æ®å¢å¼ºåå¤§å°ï¼‰ 640
        batch_size: batch size å¤§å° 8/16/32
        stride: æ¨¡å‹æœ€å¤§stride=32   [32 16 8]
        single_cls: æ•°æ®é›†æ˜¯å¦æ˜¯å•ç±»åˆ« é»˜è®¤False
        hyp: è¶…å‚åˆ—è¡¨dict ç½‘ç»œè®­ç»ƒæ—¶çš„ä¸€äº›è¶…å‚æ•°ï¼ŒåŒ…æ‹¬å­¦ä¹ ç‡ç­‰ï¼Œè¿™é‡Œä¸»è¦ç”¨åˆ°é‡Œé¢ä¸€äº›å…³äºæ•°æ®å¢å¼º(æ—‹è½¬ã€å¹³ç§»ç­‰)çš„ç³»æ•°
        augment: æ˜¯å¦è¦è¿›è¡Œæ•°æ®å¢å¼º  True
        cache: æ˜¯å¦cache_images False,ä¸å¯¹å›¾ç‰‡è¿›è¡Œç¼“å­˜
        pad: è®¾ç½®çŸ©å½¢è®­ç»ƒçš„shapeæ—¶è¿›è¡Œçš„å¡«å…… é»˜è®¤0.0
        rect: æ˜¯å¦å¼€å¯çŸ©å½¢train/test  é»˜è®¤è®­ç»ƒé›†å…³é—­ éªŒè¯é›†å¼€å¯
        rank:  å¤šå¡è®­ç»ƒæ—¶çš„è¿›ç¨‹ç¼–å· rankä¸ºè¿›ç¨‹ç¼–å·  -1ä¸”gpu=1æ—¶ä¸è¿›è¡Œåˆ†å¸ƒå¼  -1ä¸”å¤šå—gpuä½¿ç”¨DataParallelæ¨¡å¼  é»˜è®¤-1
        workers: dataloaderçš„numworks åŠ è½½æ•°æ®æ—¶çš„cpuè¿›ç¨‹æ•°
        image_weights: è®­ç»ƒæ—¶æ˜¯å¦æ ¹æ®å›¾ç‰‡æ ·æœ¬çœŸå®æ¡†åˆ†å¸ƒæƒé‡ï¼ˆå¥½åƒæ˜¯ä¸æ•°é‡æˆåæ¯”ï¼‰æ¥é€‰æ‹©å›¾ç‰‡  é»˜è®¤False
        quad: dataloaderå–æ•°æ®æ—¶, æ˜¯å¦ä½¿ç”¨collate_fn4ä»£æ›¿collate_fn  é»˜è®¤False
        prefix: æ˜¾ç¤ºä¿¡æ¯   ä¸€ä¸ªæ ‡å¿—ï¼Œå¤šä¸ºtrain/valï¼Œå¤„ç†æ ‡ç­¾æ—¶ä¿å­˜cacheæ–‡ä»¶ä¼šç”¨åˆ°
        """
    # 'è­¦å‘Š âš ï¸ --rect ä¸ DataLoader shuffle ä¸å…¼å®¹ï¼Œè®¾ç½® shuffle=False'
    if rect and shuffle:
        LOGGER.warning('WARNING âš ï¸ --rect is incompatible with DataLoader shuffle, setting shuffle=False')
        shuffle = False
    # åŒæ•°æ®é›†å¤„ç†
    with torch_distributed_zero_first(rank):  # init dataset *.cache only once if DDP
        # ç›®æ ‡ï¼šreturn torch.from_numpy(img),torch.from_numpy(img2),labels_outï¼Œself.im_files[index],self.im_files[index]ï¼Œshapes
        dataset = LoadImagesAndLabels(
            path, path2,
            imgsz,
            batch_size,
            augment=augment,  # augmentation
            hyp=hyp,  # hyperparameters
            rect=rect,  # rectangular batches
            cache_images=cache,
            single_cls=single_cls,
            stride=int(stride),
            pad=pad,
            image_weights=image_weights,
            prefix=prefix,
            prefix2=prefix2)

    batch_size = min(batch_size, len(dataset))  # 4
    nd = torch.cuda.device_count()  # number of CUDA devices #ä¸º-1
    nw = min([os.cpu_count() // max(nd, 1), batch_size if batch_size > 1 else 0, workers])  # number of workers
    sampler = None if rank == -1 else distributed.DistributedSampler(dataset, shuffle=shuffle)
    loader = DataLoader if image_weights else InfiniteDataLoader  # only DataLoader allows for attribute updates
    generator = torch.Generator()
    generator.manual_seed(6148914691236517205 + seed + RANK)
    return loader(dataset,
                  batch_size=batch_size,
                  shuffle=shuffle and sampler is None,
                  num_workers=nw,
                  sampler=sampler,
                  pin_memory=PIN_MEMORY,
                  collate_fn=LoadImagesAndLabels.collate_fn4 if quad else LoadImagesAndLabels.collate_fn,
                  worker_init_fn=seed_worker,
                  generator=generator), dataset


class InfiniteDataLoader(dataloader.DataLoader):
    """ Dataloader that reuses workers

    Uses same syntax as vanilla DataLoader
    """

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        object.__setattr__(self, 'batch_sampler', _RepeatSampler(self.batch_sampler))
        self.iterator = super().__iter__()

    def __len__(self):
        return len(self.batch_sampler.sampler)

    def __iter__(self):
        for _ in range(len(self)):
            yield next(self.iterator)


class _RepeatSampler:
    """ Sampler that repeats forever

    Args:
        sampler (Sampler)
    """

    def __init__(self, sampler):
        self.sampler = sampler

    def __iter__(self):
        while True:
            yield from iter(self.sampler)



##------------------------æ£€æµ‹å›¾åƒçš„æ—¶å€™éœ€è¦ä½¿ç”¨ï¼ˆå·²ä¿®æ”¹ï¼‰--------------------------------------
# YOLOv5 å›¾åƒ/è§†é¢‘æ•°æ®åŠ è½½å™¨ï¼Œå³â€œpython detect.py --source image.jpg/vid.mp4â€
class LoadImages:
    # YOLOv5 image/video dataloader, i.e. `python detect.py --source image.jpg/vid.mp4`
    def __init__(self, path, path2, img_size=640, stride=32, auto=True):
        p = str(Path(path).resolve())  # os-agnostic absolute path
        p2 = str(Path(path2).resolve())  # os-agnostic absolute path
        if '*' in p:
            files = sorted(glob.glob(p, recursive=True))  # glob
            files2 = sorted(glob.glob(p2, recursive=True))  # glob
        elif os.path.isdir(p):
            files = sorted(glob.glob(os.path.join(p, '*.*')))  # dir
            files2 = sorted(glob.glob(os.path.join(p2, '*.*')))  # dir
        elif os.path.isfile(p):  # å¦‚æœæ˜¯æ–‡ä»¶ç›´æ¥è·å–
            files = [p]  # files
            files2 = [p2]  # files
        else:
            raise Exception(f'ERROR: {p} does not exist')
        # åˆ†åˆ«æå–å›¾ç‰‡å’Œè§†é¢‘çš„è·¯å¾„
        images = [x for x in files if x.split('.')[-1].lower() in IMG_FORMATS]
        images2 = [x for x in files2 if x.split('.')[-1].lower() in IMG_FORMATS]
        videos = [x for x in files if x.split('.')[-1].lower() in VID_FORMATS]
        ni, nv = len(images), len(videos)  # è·å–æ•°é‡

        self.img_size = img_size
        self.stride = stride
        self.files = images + videos  # æ•´ä¸ªå›¾ç‰‡è§†é¢‘æ”¾ä¸€ä¸ªåˆ—è¡¨
        self.files2 = images2 + videos  # æ•´ä¸ªå›¾ç‰‡è§†é¢‘æ”¾ä¸€ä¸ªåˆ—è¡¨
        self.nf = ni + nv  # number of files
        self.video_flag = [False] * ni + [True] * nv  # åˆ¤æ–­æ˜¯å¦ä¸ºè§†é¢‘ï¼Œæ–¹ä¾¿åç»­å•ç‹¬å¤„ç†
        self.mode = 'image'
        self.auto = auto
        if any(videos):  # æ˜¯å¦åŒ…å«è§†é¢‘æ–‡ä»¶
            self.new_video(videos[0])  # new video
        else:
            self.cap = None
        assert self.nf > 0, f'No images or videos found in {p}. ' \
                            f'Supported formats are:\nimages: {IMG_FORMATS}\nvideos: {VID_FORMATS}'

    def __iter__(self):  # åˆ›å»ºè¿­ä»£å™¨å¯¹è±¡
        self.count = 0
        return self

    def __next__(self):  # è¾“å‡ºä¸‹ä¸€é¡¹
        if self.count == self.nf:
            raise StopIteration
        path = self.files[self.count]
        path2 = self.files2[self.count]

        if self.video_flag[self.count]:  # å¦‚æœä¸ºè§†é¢‘
            # Read video
            self.mode = 'video'
            ret_val, img0 = self.cap.read()
            while not ret_val:
                self.count += 1
                self.cap.release()
                if self.count == self.nf:  # last video
                    raise StopIteration
                else:
                    path = self.files[self.count]
                    self.new_video(path)
                    ret_val, img0 = self.cap.read()

            self.frame += 1
            s = f'video {self.count + 1}/{self.nf} ({self.frame}/{self.frames}) {path}: '

        else:
            # Read image
            self.count += 1
            img0 = cv2.imread(path)  # BGRæ ¼å¼
            img02 = cv2.imread(path2)  # BGRæ ¼å¼
            assert img0 is not None, f'Image Not Found {path}'
            s = f'image {self.count}/{self.nf} {path}: '

        # Padded resize
        img = letterbox(img0, self.img_size, stride=self.stride, auto=self.auto)[0]  # å¯¹å›¾ç‰‡ç¼©æ”¾å¡«å……
        img2 = letterbox(img02, self.img_size, stride=self.stride, auto=self.auto)[0]  # å¯¹å›¾ç‰‡ç¼©æ”¾å¡«å……

        # Convert
        img = img.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB #BGRåˆ°RGBçš„è½¬æ¢
        img = np.ascontiguousarray(img)  # å°†æ•°ç»„è½¬æ¢ä¸ºè¿ç»­ï¼Œæé«˜é€Ÿåº¦
        img2 = img2.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB #BGRåˆ°RGBçš„è½¬æ¢
        img2 = np.ascontiguousarray(img2)  # å°†æ•°ç»„è½¬æ¢ä¸ºè¿ç»­ï¼Œæé«˜é€Ÿåº¦

        return path, path2, img, img0, img2, img02, self.cap, s

    def new_video(self, path):
        self.frame = 0  # frmeè®°å½•å¸§æ•°
        self.cap = cv2.VideoCapture(path)  # åˆå§‹åŒ–è§†é¢‘å¯¹è±¡
        self.frames = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))  # æ€»å¸§æ•°

    def __len__(self):
        return self.nf  # number of files

# ä¿®æ”¹ä¸€ä¸ªé€‚åˆè‡ªå·±ç›®æ ‡æ£€æµ‹çš„ç±»
class LoadImages3:
    # YOLOv5 image/video dataloader, i.e. `python detect.py --source image.jpg/vid.mp4`
    def __init__(self, img, img2, img_size=640, stride=32, auto=True, transforms=None, vid_stride=1):
        self.img_size = img_size
        self.stride = stride
        self.files = img
        self.files2 = img2
        self.nf = 1
        self.mode = 'image'
        self.auto = auto
        self.transforms = transforms  # optional
        self.vid_stride = vid_stride  # video frame-rate stride

    # åˆ›é€ è¿­ä»£å™¨å¯¹è±¡ï¼Œå¦åˆ™å¯èƒ½æ— æ³•åœæ­¢
    def __iter__(self):
        self.count = 0
        return self

    # è¾“å‡ºä¸‹ä¸€é¡¹
    def __next__(self):
        if self.count == self.nf:
            raise StopIteration
        img = self.files
        img2 = self.files2
        # Read image
        self.count += 1
        im0 = img  # BGR
        im02 = img2

        # if self.transforms:
        #     im = self.transforms(im0)  # transforms
        #     im2 = self.transforms(im02)  # transforms
        # else:
        # print("å¤„ç†å‰",im0.shape)
        im = letterbox(im0, self.img_size, stride=self.stride, auto=self.auto)[0]  # padded resize
        # print("å¤„ç†å", im0.shape)
        im = im.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB
        im = np.ascontiguousarray(im)  # contiguous
        im2 = letterbox(im02, self.img_size, stride=self.stride, auto=self.auto)[0]  # padded resize
        im2 = im2.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB
        im2 = np.ascontiguousarray(im2)  # contiguous

        return im, im0,im2,im02

    def _cv2_rotate(self, im):
        # Rotate a cv2 video manually
        if self.orientation == 0:
            return cv2.rotate(im, cv2.ROTATE_90_CLOCKWISE)
        elif self.orientation == 180:
            return cv2.rotate(im, cv2.ROTATE_90_COUNTERCLOCKWISE)
        elif self.orientation == 90:
            return cv2.rotate(im, cv2.ROTATE_180)
        return im

    def __len__(self):
        return self.nf  # number of files
# æ ¹æ®å›¾åƒè·¯å¾„ï¼Œæ‰¾åˆ°æ ‡ç­¾è·¯å¾„ï¼ˆå›¾åƒ1ï¼‰
def img2label_paths(img_paths):
    # Define label paths as a function of image paths
    sa, sb = f'{os.sep}images{os.sep}', f'{os.sep}labels{os.sep}'  # /images/, /labels/ substrings
    return [sb.join(x.rsplit(sa, 1)).rsplit('.', 1)[0] + '.txt' for x in img_paths]

# æ ¹æ®å›¾åƒè·¯å¾„ï¼Œæ‰¾åˆ°æ ‡ç­¾è·¯å¾„ï¼ˆå›¾åƒ2ï¼‰
def img2label_paths2(img_paths):
    # Define label paths as a function of image paths
    sa, sb = os.sep + 'images2' + os.sep, os.sep + 'labels' + os.sep  # /images/, /labels/ substrings
    return [sb.join(x.rsplit(sa, 1)).rsplit('.', 1)[0] + '.txt' for x in img_paths]

# å›¾ç‰‡æ ‡ç­¾åŠ è½½å™¨ï¼ˆå›¾ç‰‡1å’Œå›¾ç‰‡2å’Œæ ‡ç­¾è¿›è¡Œæ‰“åŒ…ï¼‰
class LoadImagesAndLabels(Dataset):
    # YOLOv5 train_loader/val_loader, loads images and labels for training and validation(ä¸ºè®­ç»ƒåŠ è½½å›¾åƒå’Œæ ‡ç­¾)
    cache_version = 0.6  # dataset labels *.cache version
    rand_interp_methods = [cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4]

    def __init__(self,
                 path, path2,
                 img_size=640,
                 batch_size=16,
                 augment=False,
                 hyp=None,
                 rect=False,
                 image_weights=False,
                 cache_images=False,
                 single_cls=False,
                 stride=32,
                 pad=0.0,
                 min_items=0,
                 prefix='',
                 prefix2=''):
        # åˆ›å»ºå‚æ•°
        self.img_size = img_size
        self.augment = augment  # æ•°æ®å¢å¼º
        self.hyp = hyp  # è¶…å‚æ•°
        self.image_weights = image_weights  # å›¾ç‰‡é‡‡é›†æƒé‡
        self.rect = False if image_weights else rect  # çŸ©å½¢è®­ç»ƒ
        # mosaicæ•°æ®å¢å¼º
        self.mosaic = self.augment and not self.rect  # load 4 images at a time into a mosaic (only during training)
        self.mosaic_border = [-img_size // 2, -img_size // 2]
        self.stride = stride  # æœ€å¤§ä¸‹é‡‡æ ·
        self.path = path
        self.path2 = path2
        self.albumentations = Albumentations() if augment else None
        # ä¸€ä¸ªæ ‡å¿—train/val
        self.prefix = prefix
        self.prefix2 = prefix2
        # æ‰¾åˆ°pathä¸­txtæ–‡ä»¶æ¯ä¸€è¡Œå›¾åƒè·¯å¾„im_files
        try:
            f = []  # image files
            # 'D:\\project1\\sf6_dection\\objection_detection4\\yolov5-master\\VOCData\\dataSet_path\\train.txt'
            for p in path if isinstance(path, list) else [path]:
                # æå–æ–‡ä»¶å
                p = Path(p)  # os-agnostic
                # å¦‚æœè·¯å¾„pä¸ºæ–‡ä»¶å¤¹
                if p.is_dir():  # dir
                    f += glob.glob(str(p / '**' / '*.*'), recursive=True)
                    # f = list(p.rglob('*.*'))  # pathlib
                # å¦‚æœè·¯å¾„pä¸ºæ–‡ä»¶
                elif p.is_file():  # file
                    # è¯»å–æ–‡ä»¶ï¼Œå¹¶è‡ªåŠ¨å…³é—­
                    with open(p) as t:
                        # .read()è¯»å–æ–‡ä»¶ï¼Œstrip()å»é™¤é¦–å°¾ç©ºæ ¼ï¼Œ.splitlinesæŒ‰æ¯ä¸€è¡Œè¯»å–æ–‡ä»¶
                        t = t.read().strip().splitlines()
                        # p.parentä¸ºä¸Šä¸€å±‚çš„æ–‡ä»¶å¤¹å+åŠ os.sep=//
                        parent = str(p.parent) + os.sep
                        # fä¸ºå›¾åƒimagesçš„ç›¸å¯¹è·¯å¾„
                        f += [x.replace('./', parent, 1) if x.startswith('./') else x for x in t]  # to global path
                        # f += [p.parent / x.lstrip(os.sep) for x in t]  # to global path (pathlib)
                else:
                    raise FileNotFoundError(f'{prefix}{p} does not exist')
            # im_filesä¸ºå¯¹åº”å›¾åƒä½ç½®.jpg
            self.im_files = sorted(x.replace('/', os.sep) for x in f if x.split('.')[-1].lower() in IMG_FORMATS)
            # self.img_files = sorted([x for x in f if x.suffix[1:].lower() in IMG_FORMATS])  # pathlib
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å¯¹åº”æ–‡ä»¶ï¼Œåˆ™æ‰“å°æ²¡æœ‰No images found
            assert self.im_files, f'{prefix}No images found'
        except Exception as e:
            raise Exception(f'{prefix}Error loading data from {path}: {e}\n{HELP_URL}') from e
        # æ‰¾åˆ°path2ä¸­txtæ–‡ä»¶æ¯ä¸€è¡Œå›¾åƒè·¯å¾„im_files2ï¼ˆæ”¹å˜fä¸ºf2ï¼Œpå˜ä¸ºp2,t->t2ï¼‰
        try:
            f2 = []  # image files
            # 'D:\\project1\\sf6_dection\\objection_detection4\\yolov5-master\\VOCData\\dataSet_path\\train.txt'
            for p2 in path2 if isinstance(path2, list) else [path2]:
                # æå–æ–‡ä»¶å
                p2 = Path(p2)  # os-agnostic
                # å¦‚æœè·¯å¾„pä¸ºæ–‡ä»¶å¤¹
                if p2.is_dir():  # dir
                    f2 += glob.glob(str(p2 / '**' / '*.*'), recursive=True)
                    # f = list(p.rglob('*.*'))  # pathlib
                # å¦‚æœè·¯å¾„pä¸ºæ–‡ä»¶
                elif p2.is_file():  # file
                    # è¯»å–æ–‡ä»¶ï¼Œå¹¶è‡ªåŠ¨å…³é—­
                    with open(p2) as t2:
                        # .read()è¯»å–æ–‡ä»¶ï¼Œstrip()å»é™¤é¦–å°¾ç©ºæ ¼ï¼Œ.splitlinesæŒ‰æ¯ä¸€è¡Œè¯»å–æ–‡ä»¶
                        t2 = t2.read().strip().splitlines()
                        # p.parentä¸ºä¸Šä¸€å±‚çš„æ–‡ä»¶å¤¹å+åŠ os.sep=//
                        parent = str(p2.parent) + os.sep
                        # f2ä¸ºå›¾åƒimagesçš„ç›¸å¯¹è·¯å¾„
                        f2 += [x.replace('./', parent, 1) if x.startswith('./') else x for x in t2]  # to global path
                        # f += [p.parent / x.lstrip(os.sep) for x in t]  # to global path (pathlib)
                else:
                    raise FileNotFoundError(f'{prefix2}{p2} does not exist')
            # im_filesä¸ºå¯¹åº”å›¾åƒä½ç½®.jpg
            self.im_files2 = sorted(x.replace('/', os.sep) for x in f2 if x.split('.')[-1].lower() in IMG_FORMATS)
            # self.img_files = sorted([x for x in f if x.suffix[1:].lower() in IMG_FORMATS])  # pathlib
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å¯¹åº”æ–‡ä»¶ï¼Œåˆ™æ‰“å°æ²¡æœ‰No images found
            assert self.im_files2, f'{prefix2}No images found'
        except Exception as e:
            raise Exception(f'{prefix2}Error loading data from {path2}: {e}\n{HELP_URL}') from e

        # Check cache
        # ä¸ºå¯¹åº”å›¾åƒæ ‡ç­¾æ ‡ç­¾ä½ç½®txt(æ ‡ç­¾åªæœ‰ä¸€ä¸ªï¼Œæ‰€ä»¥ä¸éœ€è¦labels2)
        self.label_files = img2label_paths(self.im_files)  # labels
        self.label_files2 = img2label_paths2(self.im_files2)  # labels
        # self.label_files = img2label_paths(self.im_files)  # labels

        # cache_path=D:\project1\sf6_dection\objection_detection4\yolov5-master\VOCData\dataSet_path\train.cache
        cache_path = (p if p.is_file() else Path(self.label_files[0]).parent).with_suffix('.cache')
        cache_path2 = (p2 if p2.is_file() else Path(self.label_files2[0]).parent).with_suffix('.cache')
        # path
        try:
            # å¦‚æœæœ‰cacheæ–‡ä»¶ï¼Œç›´æ¥åŠ è½½ï¼Œexist=Trueï¼›æ˜¯å¦å·²ä»cacheæ–‡ä»¶ä¸­è¯»å–nf,nm,neç­‰ä¿¡æ¯
            cache, exists = np.load(cache_path, allow_pickle=True).item(), True  # load dict
            # å¦‚æœå›¾åƒç‰ˆæœ¬ä¿¡æ¯æˆ–æ–‡ä»¶åˆ—è¡¨çš„hashå€¼å¯¹ä¸ä¸Šå·ï¼Œå¯èƒ½æœ¬åœ°æ•°æ®é›†å›¾ç‰‡å’ŒLabelå¯èƒ½å‘ç”Ÿäº†å˜åŒ–ï¼Œé‡æ–°cache labelæ–‡ä»¶
            assert cache['version'] == self.cache_version  # matches current version
            assert cache['hash'] == get_hash(self.label_files + self.im_files)  # identical hash
        except Exception:
            # å¦åˆ™è°ƒç”¨cache_labelsç¼“å­˜æ ‡ç­¾åŠæ ‡ç­¾ç›¸å…³ä¿¡æ¯
            cache, exists = self.cache_labels(cache_path,self.im_files, self.label_files, prefix), False  # run cache ops
        # path2
        try:
            # å¦‚æœæœ‰cacheæ–‡ä»¶ï¼Œç›´æ¥åŠ è½½ï¼Œexist=Trueï¼›æ˜¯å¦å·²ä»cacheæ–‡ä»¶ä¸­è¯»å–nf,nm,neç­‰ä¿¡æ¯
            cache2, exists = np.load(cache_path2, allow_pickle=True).item(), True  # load dict
            # å¦‚æœå›¾åƒç‰ˆæœ¬ä¿¡æ¯æˆ–æ–‡ä»¶åˆ—è¡¨çš„hashå€¼å¯¹ä¸ä¸Šå·ï¼Œå¯èƒ½æœ¬åœ°æ•°æ®é›†å›¾ç‰‡å’ŒLabelå¯èƒ½å‘ç”Ÿäº†å˜åŒ–ï¼Œé‡æ–°cache labelæ–‡ä»¶
            assert cache2['version'] == self.cache_version  # matches current version
            assert cache2['hash'] == get_hash(self.label_files2 + self.im_files2)  # identical hash
        except Exception:
            # å¦åˆ™è°ƒç”¨cache_labelsç¼“å­˜æ ‡ç­¾åŠæ ‡ç­¾ç›¸å…³ä¿¡æ¯
            cache2, exists = self.cache_labels(cache_path2,self.im_files2, self.label_files2, prefix2), False  # run cache ops

        # Display cache
        # æ‰“å°cacheçš„ç»“æœnf nm ne nc n=æ‰¾åˆ°çš„æ ‡ç­¾æ•°é‡ æ¼æ‰çš„æ ‡ç­¾æ•°é‡ ï¼Œç©ºçš„æ ‡ç­¾æ•°é‡ ï¼ŒæŸåçš„æ ‡ç­¾æ•°é‡ï¼Œæ€»çš„
        nf, nm, ne, nc, n = cache.pop('results')  # found, missing, empty, corrupt, total
        if exists and LOCAL_RANK in {-1, 0}:
            d = f'Scanning {cache_path}... {nf} images, {nm + ne} backgrounds, {nc} corrupt'
            # å±•ç¤ºcache result
            tqdm(None, desc=prefix + d, total=n, initial=n, bar_format=TQDM_BAR_FORMAT)  # display cache results
            if cache['msgs']:
                LOGGER.info('\n'.join(cache['msgs']))  # display warnings
        # æ•°æ®é›†æ²¡æœ‰æ ‡ç­¾ä¿¡æ¯ï¼Œå°±å‘å‡ºè­¦å‘Šå¹¶æ˜¾ç¤ºæ ‡ç­¾Labelä¸‹è½½help_url
        assert nf > 0 or not augment, f'{prefix}No labels found in {cache_path}, can not start training. {HELP_URL}'

        nf2, nm2, ne2, nc2, n2 = cache2.pop('results')  # found, missing, empty, corrupt, total
        if exists and LOCAL_RANK in {-1, 0}:
            d = f'Scanning {cache_path2}... {nf2} images, {nm2 + ne2} backgrounds, {nc2} corrupt'
            # å±•ç¤ºcache result
            tqdm(None, desc=prefix2 + d, total=n2, initial=n2, bar_format=TQDM_BAR_FORMAT)  # display cache results
            if cache2['msgs']:
                LOGGER.info('\n'.join(cache2['msgs']))  # display warnings
        # æ•°æ®é›†æ²¡æœ‰æ ‡ç­¾ä¿¡æ¯ï¼Œå°±å‘å‡ºè­¦å‘Šå¹¶æ˜¾ç¤ºæ ‡ç­¾Labelä¸‹è½½help_url
        assert nf2 > 0 or not augment, f'{prefix2}No labels found in {cache_path2}, can not start training. {HELP_URL}'

        # Read cache
        # å…ˆä»cacheä¸­å»é™¤cacheæ–‡ä»¶ä¸­å…¶å®ƒæ— å…³é”®å€¼å¦‚ï¼šâ€œhashâ€ï¼Œâ€œverionâ€,"mags"ç­‰
        [cache.pop(k) for k in ('hash', 'version', 'msgs')]  # remove items
        # åªå‰©ä¸‹cache[img_file]=[l, shape, segments]

        # cache.values(): å–cacheä¸­æ‰€æœ‰å€¼ å¯¹åº”æ‰€æœ‰l, shape, segments
        # labels: å¦‚æœæ•°æ®é›†æ‰€æœ‰å›¾ç‰‡ä¸­æ²¡æœ‰ä¸€ä¸ªå¤šè¾¹å½¢label  labelså­˜å‚¨çš„labelå°±éƒ½æ˜¯åŸå§‹label(éƒ½æ˜¯æ­£å¸¸çš„çŸ©å½¢label)
        #         å¦åˆ™å°†æ‰€æœ‰å›¾ç‰‡æ­£å¸¸gtçš„labelå­˜å…¥labels ä¸æ­£å¸¸gt(å­˜åœ¨ä¸€ä¸ªå¤šè¾¹å½¢)ç»è¿‡segments2boxesè½¬æ¢ä¸ºæ­£å¸¸çš„çŸ©å½¢label
        # shapes: æ‰€æœ‰å›¾ç‰‡çš„shape
        # self.segments: å¦‚æœæ•°æ®é›†æ‰€æœ‰å›¾ç‰‡ä¸­æ²¡æœ‰ä¸€ä¸ªå¤šè¾¹å½¢label  self.segments=None
        #                å¦åˆ™å­˜å‚¨æ•°æ®é›†ä¸­æ‰€æœ‰å­˜åœ¨å¤šè¾¹å½¢gtçš„å›¾ç‰‡çš„æ‰€æœ‰åŸå§‹label(è‚¯å®šæœ‰å¤šè¾¹å½¢label ä¹Ÿå¯èƒ½æœ‰çŸ©å½¢æ­£å¸¸label æœªçŸ¥æ•°)
        # zip æ˜¯å› ä¸ºcacheä¸­æ‰€æœ‰labelsã€shapesã€segmentsä¿¡æ¯éƒ½æ˜¯æŒ‰æ¯å¼ imgåˆ†å¼€å­˜å‚¨çš„, zipæ˜¯å°†æ‰€æœ‰å›¾ç‰‡å¯¹åº”çš„ä¿¡æ¯å åœ¨ä¸€èµ·

        labels, shapes, self.segments = zip(*cache.values())
        # æ¡†çš„æ€»ä¸ªæ•°
        nl = len(np.concatenate(labels, 0))  # number of labels
        assert nl > 0 or not augment, f'{prefix}All labels empty in {cache_path}, can not start training. {HELP_URL}'
        self.labels = list(labels)
        self.shapes = np.array(shapes)
        # æ›´æ–°æ‰€æœ‰å›¾ç‰‡çš„img_filesä¿¡æ¯
        self.im_files = list(cache.keys())  # update å›¾ç‰‡åˆ—è¡¨
        # æ›´æ–°æ‰€æœ‰å›¾ç‰‡çš„label_filesä¿¡æ¯
        self.label_files = img2label_paths(cache.keys())  # update æ ‡ç­¾åˆ—è¡¨

        # Read cache2
        # å…ˆä»cacheä¸­å»é™¤cacheæ–‡ä»¶ä¸­å…¶å®ƒæ— å…³é”®å€¼å¦‚ï¼šâ€œhashâ€ï¼Œâ€œverionâ€,"mags"ç­‰
        [cache2.pop(k) for k in ('hash', 'version', 'msgs')]  # remove items
        # [cache2.pop(k) for k in ('hash', 'version', 'msgs')]  # remove items
        # åªå‰©ä¸‹cache[img_file]=[l, shape, segments]

        # cache.values(): å–cacheä¸­æ‰€æœ‰å€¼ å¯¹åº”æ‰€æœ‰l, shape, segments
        # labels: å¦‚æœæ•°æ®é›†æ‰€æœ‰å›¾ç‰‡ä¸­æ²¡æœ‰ä¸€ä¸ªå¤šè¾¹å½¢label  labelså­˜å‚¨çš„labelå°±éƒ½æ˜¯åŸå§‹label(éƒ½æ˜¯æ­£å¸¸çš„çŸ©å½¢label)
        #         å¦åˆ™å°†æ‰€æœ‰å›¾ç‰‡æ­£å¸¸gtçš„labelå­˜å…¥labels ä¸æ­£å¸¸gt(å­˜åœ¨ä¸€ä¸ªå¤šè¾¹å½¢)ç»è¿‡segments2boxesè½¬æ¢ä¸ºæ­£å¸¸çš„çŸ©å½¢label
        # shapes: æ‰€æœ‰å›¾ç‰‡çš„shape
        # self.segments: å¦‚æœæ•°æ®é›†æ‰€æœ‰å›¾ç‰‡ä¸­æ²¡æœ‰ä¸€ä¸ªå¤šè¾¹å½¢label  self.segments=None
        #                å¦åˆ™å­˜å‚¨æ•°æ®é›†ä¸­æ‰€æœ‰å­˜åœ¨å¤šè¾¹å½¢gtçš„å›¾ç‰‡çš„æ‰€æœ‰åŸå§‹label(è‚¯å®šæœ‰å¤šè¾¹å½¢label ä¹Ÿå¯èƒ½æœ‰çŸ©å½¢æ­£å¸¸label æœªçŸ¥æ•°)
        # zip æ˜¯å› ä¸ºcacheä¸­æ‰€æœ‰labelsã€shapesã€segmentsä¿¡æ¯éƒ½æ˜¯æŒ‰æ¯å¼ imgåˆ†å¼€å­˜å‚¨çš„, zipæ˜¯å°†æ‰€æœ‰å›¾ç‰‡å¯¹åº”çš„ä¿¡æ¯å åœ¨ä¸€èµ·

        labels2, shapes2, self.segments2 = zip(*cache2.values())

        self.labels2 = list(labels2)
        self.shapes2 = np.array(shapes2)
        # æ›´æ–°æ‰€æœ‰å›¾ç‰‡çš„img_filesä¿¡æ¯
        self.im_files2 = list(cache2.keys())  # update å›¾ç‰‡åˆ—è¡¨
        # æ›´æ–°æ‰€æœ‰å›¾ç‰‡çš„label_filesä¿¡æ¯
        self.label_files2 = img2label_paths2(cache2.keys())  # update æ ‡ç­¾åˆ—è¡¨
        n = len(self.shapes)  # number of images
        # å›¾åƒçš„æ•°é‡/batch_size
        bi = np.floor(np.arange(n) / batch_size).astype(int)  # batch index
        # ä»¥è¿™æ ·batch_size,ä¸€è½®è®­ç»ƒéœ€è¦å¾ªç¯çš„æ¬¡æ•°
        nb = bi[-1] + 1  # number of batches
        self.batch = bi  # batch index of image
        self.n = n
        self.indices = range(n)
        # Create indices
        # å›¾åƒçš„æ•°é‡
        n2 = len(self.shapes2)  # number of images
        # å›¾åƒçš„æ•°é‡/batch_size
        bi2 = np.floor(np.arange(n2) / batch_size).astype(int)  # batch index
        # ä»¥è¿™æ ·batch_size,ä¸€è½®è®­ç»ƒéœ€è¦å¾ªç¯çš„æ¬¡æ•°
        nb2 = bi2[-1] + 1  # number of batches
        self.batch2 = bi2  # batch index of image
        self.n2 = n2
        self.indices2 = range(n2)

        # Update labels
        include_class = []  # filter labels to include only these classes (optional)
        self.segments = list(self.segments)
        include_class_array = np.array(include_class).reshape(1, -1)
        for i, (label, segment) in enumerate(zip(self.labels, self.segments)):
            if include_class:
                j = (label[:, 0:1] == include_class_array).any(1)
                self.labels[i] = label[j]
                if segment:
                    self.segments[i] = [segment[idx] for idx, elem in enumerate(j) if elem]
            if single_cls:  # single-class training, merge all classes into 0
                self.labels[i][:, 0] = 0

        # Update labels2
        include_class2 = []  # filter labels to include only these classes (optional)
        self.segments2 = list(self.segments2)
        include_class_array2 = np.array(include_class2).reshape(1, -1)
        # å–å‡ºæ ‡ç­¾ï¼ˆæŒ‰é¡ºåºå–å‡ºæ ‡ç­¾ï¼‰
        for i, (label2, segment2) in enumerate(zip(self.labels2, self.segments2)):
            if include_class2:
                j = (label2[:, 0:1] == include_class_array2).any(1)
                self.labels2[i] = label2[j]
                if segment2:
                    self.segments2[i] = [segment2[idx] for idx, elem in enumerate(j) if elem]
            if single_cls:  # single-class training, merge all classes into 0
                self.labels2[i][:, 0] = 0

        # Rectangular Trainingï¼ˆçŸ©å½¢è®­ç»ƒï¼Œè¿™è¾¹å¥½åƒæ²¡æœ‰ä½¿ç”¨ï¼‰
        # ä¸»è¦æ³¨æ„shapesçš„ç”Ÿæˆï¼Œè¿™ä¸€æ­¥å¾ˆé‡è¦ï¼Œå› ä¸ºå¦‚æœé‡‡æ ·çŸ©é˜µè®­ç»ƒï¼Œé‚£ä¹ˆæ•´ä¸ªbatchè¦ä¸€æ ·
        if self.rect:

            ######## ç¬¬ä¸€éƒ¨åˆ†
            # Sort by aspect ratio
            # æ’åº
            s = self.shapes  # whå®½é«˜
            ar = s[:, 1] / s[:, 0]  # aspect ratioå®½é«˜æ¯”
            irect = ar.argsort()  # æ’åº
            self.im_files = [self.im_files[i] for i in irect]
            self.label_files = [self.label_files[i] for i in irect]
            self.labels = [self.labels[i] for i in irect]
            self.segments = [self.segments[i] for i in irect]
            self.shapes = s[irect]  # wh
            ar = ar[irect]

            # è®¡ç®—æ¯ä¸ªbatché‡‡ç”¨ç»Ÿä¸€å°ºå¯¸
            # Set training image shapes
            shapes = [[1, 1]] * nb
            for i in range(nb):
                ari = ar[bi == i]
                mini, maxi = ari.min(), ari.max()
                if maxi < 1:
                    shapes[i] = [maxi, 1]
                elif mini > 1:
                    shapes[i] = [1, 1 / mini]
            # è®¡ç®—è¦æ±‚æ¯ä¸ªbatchè¾“å…¥ç½‘ç»œçš„shapeå€¼ï¼ˆå‘ä¸Šè®¾ç½®ä¸º32çš„æ•´æ•°å€ï¼‰
            # è¦æ±‚æ¯ä¸ªbatch_shapesçš„é«˜å®½éƒ½æ˜¯32çš„æ•´æ•°å€ï¼Œæ‰€ä»¥è¦å…ˆé™¤ä»¥32ï¼Œå†å–æ•´å†ä¹˜ä»¥32
            self.batch_shapes = np.ceil(np.array(shapes) * img_size / stride + pad).astype(int) * stride

            ####### ç¬¬äºŒéƒ¨åˆ†
            s2 = self.shapes2  # whå®½é«˜
            ar2 = s2[:, 1] / s2[:, 0]  # aspect ratioå®½é«˜æ¯”
            irect2 = ar2.argsort()  # æ’åº
            self.im_files2 = [self.im_files2[i] for i in irect2]
            self.label_files2 = [self.label_files2[i] for i in irect2]
            self.labels2 = [self.labels2[i] for i in irect2]
            self.segments2 = [self.segments2[i] for i in irect2]
            self.shapes2 = s[irect2]  # wh
            ar2 = ar2[irect2]

            # è®¡ç®—æ¯ä¸ªbatché‡‡ç”¨ç»Ÿä¸€å°ºå¯¸
            # Set training image shapes
            shapes2 = [[1, 1]] * nb2
            for i in range(nb2):
                ari2 = ar2[bi2 == i]
                mini, maxi = ari2.min(), ari2.max()
                if maxi < 1:
                    shapes2[i] = [maxi, 1]
                elif mini > 1:
                    shapes2[i] = [1, 1 / mini]
            # è®¡ç®—è¦æ±‚æ¯ä¸ªbatchè¾“å…¥ç½‘ç»œçš„shapeå€¼ï¼ˆå‘ä¸Šè®¾ç½®ä¸º32çš„æ•´æ•°å€ï¼‰
            # è¦æ±‚æ¯ä¸ªbatch_shapesçš„é«˜å®½éƒ½æ˜¯32çš„æ•´æ•°å€ï¼Œæ‰€ä»¥è¦å…ˆé™¤ä»¥32ï¼Œå†å–æ•´å†ä¹˜ä»¥32
            self.batch_shapes2 = np.ceil(np.array(shapes2) * img_size / stride + pad).astype(int) * stride

        # Cache images into RAM/disk for faster training
        # è¿™è¾¹å¥½åƒä¹Ÿæ²¡æœ‰ä½¿ç”¨
        if cache_images == 'ram' and not self.check_cache_ram(prefix=prefix):
            cache_images = False
        # å°†å›¾ç‰‡åŠ è½½åˆ°å†…å­˜ä¸­ï¼Œæ­¤å¤„ä½¿ç”¨äº†å¤šçº¿ç¨‹åŠ è½½å›¾ç‰‡ï¼Œå¯ä»¥å¾ˆå¿«çš„æé«˜é€Ÿåº¦
        # æ³¨ï¼šåœ¨
        self.ims = [None] * n
        self.ims2 = [None] * n2
        # å›¾åƒè½¬æˆå¯¹åº”çš„npy
        self.npy_files = [Path(f).with_suffix('.npy') for f in self.im_files]
        self.npy_files2 = [Path(f).with_suffix('.npy') for f in self.im_files2]

        # è¿™è¾¹ä¹Ÿæ²¡æ‰§è¡Œ(cache_images)ï¼Œä¸å¯¹å›¾åƒè¿›è¡Œç¼“å­˜

    # # å¥½åƒæ²¡æœ‰è¢«ä½¿ç”¨
    # def check_cache_ram(self, safety_margin=0.1, prefix=''):
    #     # Check image caching requirements vs available memory
    #     b, gb = 0, 1 << 30  # bytes of cached images, bytes per gigabytes
    #     n = min(self.n, 30)  # extrapolate from 30 random images
    #     for _ in range(n):
    #         im = cv2.imread(random.choice(self.im_files))  # sample image
    #         ratio = self.img_size / max(im.shape[0], im.shape[1])  # max(h, w)  # ratio
    #         b += im.nbytes * ratio ** 2
    #     mem_required = b * self.n / n  # GB required to cache dataset into RAM
    #     mem = psutil.virtual_memory()
    #     cache = mem_required * (1 + safety_margin) < mem.available  # to cache or not to cache, that is the question
    #     if not cache:
    #         LOGGER.info(f'{prefix}{mem_required / gb:.1f}GB RAM required, '
    #                     f'{mem.available / gb:.1f}/{mem.total / gb:.1f}GB available, '
    #                     f"{'caching images âœ…' if cache else 'not caching images âš ï¸'}")
    #     return cache

    # åœ¨ä¸Šé¢çš„_init_å‡½æ•°è°ƒç”¨ï¼Œç”¨äºç¼“å­˜æ ‡ç­¾åŠæ ‡ç­¾ç›¸å…³ä¿¡æ¯
    # def cache_labels(self, path=Path('./labels.cache'), prefix=''):
    #     # Cache dataset labels, check images and read shapes
    #     x = {}  # dict
    #     nm, nf, ne, nc, msgs = 0, 0, 0, 0, []  # number missing, found, empty, corrupt, messages
    #     desc = f'{prefix}Scanning {path.parent / path.stem}...'
    #     with Pool(NUM_THREADS) as pool:
    #         pbar = tqdm(pool.imap(verify_image_label, zip(self.im_files, self.label_files, repeat(prefix))),
    #                     desc=desc,
    #                     total=len(self.im_files),
    #                     bar_format=TQDM_BAR_FORMAT)
    #         for im_file, lb, shape, segments, nm_f, nf_f, ne_f, nc_f, msg in pbar:
    #             nm += nm_f
    #             nf += nf_f
    #             ne += ne_f
    #             nc += nc_f
    #             if im_file:
    #                 x[im_file] = [lb, shape, segments]
    #             if msg:
    #                 msgs.append(msg)
    #             pbar.desc = f'{desc} {nf} images, {nm + ne} backgrounds, {nc} corrupt'
    #
    #     pbar.close()
    #     if msgs:
    #         LOGGER.info('\n'.join(msgs))
    #     if nf == 0:
    #         LOGGER.warning(f'{prefix}WARNING âš ï¸ No labels found in {path}. {HELP_URL}')
    #     x['hash'] = get_hash(self.label_files + self.im_files)
    #     x['results'] = nf, nm, ne, nc, len(self.im_files)
    #     x['msgs'] = msgs  # warnings
    #     x['version'] = self.cache_version  # cache version
    #     try:
    #         np.save(path, x)  # save cache for next time
    #         path.with_suffix('.cache.npy').rename(path)  # remove .npy suffix
    #         LOGGER.info(f'{prefix}New cache created: {path}')
    #     except Exception as e:
    #         LOGGER.warning(f'{prefix}WARNING âš ï¸ Cache directory {path.parent} is not writeable: {e}')  # not writeable
    #     return x
    # ç”Ÿæˆcacheæ–‡ä»¶ï¼ˆå·²ä¿®æ”¹ï¼‰
    def cache_labels(self, path, im_files, label_files, prefix=''):
        cache_version = 0.6
        # Cache dataset labels, check images and read shapes
        x = {}  # dict
        nm, nf, ne, nc, msgs = 0, 0, 0, 0, []  # number missing, found, empty, corrupt, messages
        desc = f"{prefix}Scanning '{path.parent / path.stem}' images and labels..."
        with Pool(NUM_THREADS) as pool:
            pbar = tqdm(pool.imap(verify_image_label, zip(im_files, label_files, repeat(prefix))),desc=desc, total=len(im_files), bar_format=BAR_FORMAT)
            for im_file, lb, shape, segments, nm_f, nf_f, ne_f, nc_f, msg in pbar:
                nm += nm_f
                nf += nf_f
                ne += ne_f
                nc += nc_f
                if im_file:
                    x[im_file] = [lb, shape, segments]  # ä¿å­˜ä¸ºå­—å…¸
                if msg:
                    msgs.append(msg)
                pbar.desc = f"{desc}{nf} found, {nm} missing, {ne} empty, {nc} corrupt"

        pbar.close()
        if msgs:
            LOGGER.info('\n'.join(msgs))
        if nf == 0:
            LOGGER.warning(f'{prefix}WARNING: No labels found in {path}. See {HELP_URL}')
        x['hash'] = get_hash(label_files + im_files)
        x['results'] = nf, nm, ne, nc, len(im_files)
        x['msgs'] = msgs  # warnings
        x['version'] = cache_version  # cache version
        try:
            np.save(path, x)  # save cache for next time ä¿å­˜æœ¬åœ°æ–¹ä¾¿ä¸‹æ¬¡ä½¿ç”¨
            path.with_suffix('.cache.npy').rename(path)  # remove .npy suffix
            LOGGER.info(f'{prefix}New cache created: {path}')
        except Exception as e:
            LOGGER.warning(f'{prefix}WARNING: Cache directory {path.parent} is not writeable: {e}')  # not writeable
        return x

    # å®é™…è¾“å…¥å›¾åƒå¤§å°å’Œè¾“å…¥æ¨¡å‹çš„å›¾åƒéœ€è¦è¿›è¡Œresizeæ“ä½œ
    # # åŠ è½½å›¾ç‰‡å¹¶æ ¹æ®è®¾å®šè¾“å…¥å¤§å°ä¸å›¾ç‰‡æºå¤§å°æ¯”ä¾‹è¿›è¡Œresize
    def __len__(self):
        return len(self.im_files)

    #
    # def __iter__(self):
    #     self.count = -1
    #     print('ran dataset iter')
    #     #self.shuffled_vector = np.random.permutation(self.nF) if self.augment else np.arange(self.nF)
    #     return self

    # æ•°æ®å¢å¼ºï¼ˆå›¾åƒå¢å¼ºï¼Œä½†å›¾åƒ1ã€å’Œå›¾åƒ2éœ€è¦è¿›è¡Œç›¸åŒçš„æ•°æ®å¢å¼ºï¼Œå¦åˆ™èåˆåä½ç½®å‡ºé”™ï¼Œæ ‡ç­¾æ–‡ä»¶ä¹Ÿéœ€è¦è¿›è¡Œç›¸åŒçš„ä½ç½®ä¿®æ”¹ï¼‰
    def __getitem__(self, index):
        # å›¾ç‰‡ç´¢å¼•index
        i = self.indices[index]  # linear, shuffled, or image_weights
        i2 = self.indices2[index]  # linear, shuffled, or image_weights
        # è¶…å‚æ•° åŒ…å«å¾ˆå¤šæ•°æ®å¢å¼ºè¶…å‚æ•°
        hyp = self.hyp
        # æ˜¯å¦è¿›è¡Œé©¬èµ›å…‹æ•°æ®å¢å¼º
        mosaic = self.mosaic and random.random() < hyp['mosaic']
        if mosaic:
            # Load mosaicï¼ˆè¢«è°ƒç”¨ï¼‰
            img, img2, labels = self.load_mosaic(index)
            shapes = None
            shapes2 = None
            # æŸ¥çœ‹é©¬èµ›å…‹ç»“æœå›¾
            # cv2.imshow("masaic", img)
            # cv2.waitKey(0)
            # cv2.destroyAllWindows()

            # # MixUp augmentationï¼ˆæ··åˆå›¾åƒæ•°æ®å¢å¼ºï¼‰
            # if random.random() < hyp['mixup']:
            #     # img:   ä¸¤å¼ å›¾ç‰‡èåˆä¹‹åçš„å›¾ç‰‡--numpy (640, 640, 3)
            #     # labels: ä¸¤å¼ å›¾ç‰‡èåˆä¹‹åçš„æ ‡ç­¾--label [M+N, cls+x1y1x2y2]
            #     img, labels = mixup(img, labels, *self.load_mosaic(random.randint(0, self.n - 1)))
        # ä¸è¿›è¡Œé©¬èµ›å…‹
        else:
            # Load imageï¼ˆè½½å…¥å›¾åƒï¼‰
            # 1ã€img: resizeåçš„å›¾ç‰‡ï¼› 2ã€(h0, w0): åŸå§‹å›¾ç‰‡çš„hwï¼› 3ã€(h, w): resizeåçš„å›¾ç‰‡çš„hw
            img, (h0, w0), (h, w) = self.load_image(index)
            img2, (h02, w02), (h2, w2) = self.load_image2(index)
            # Letterbox
            # 4ã€Letterbox ä¸»è¦è¿ç”¨äºvalæˆ–è€…detect
            # 4.1 ç¡®å®šè¿™å¼ å½“å‰å›¾ç‰‡letterboxä¹‹åçš„shape
            # å¦‚æœä¸ç”¨self.rectçŸ©å½¢è®­ç»ƒshapeå°±æ˜¯self.img_size
            shape = self.batch_shapes[self.batch[index]] if self.rect else self.img_size  # final letterboxed shape
            # 4.2 letterbox è¿™ä¸€æ­¥å°†ç¬¬ä¸€æ­¥ç¼©æ”¾å¾—åˆ°çš„å›¾ç‰‡å†ç¼©æ”¾åˆ°å½“å‰batchæ‰€éœ€è¦çš„å°ºåº¦
            # çŸ©å½¢æ¨ç†éœ€è¦ä¸€ä¸ªbatchçš„æ‰€æœ‰å›¾ç‰‡çš„shapeå¿…é¡»ç›¸åŒ
            # è¿™é‡Œæ²¡æœ‰ç¼©æ”¾æ“ä½œï¼Œæ‰€ä»¥è¿™é‡Œçš„ratioæ°¸è¿œéƒ½æ˜¯(1.0, 1.0)  pad=(0.0, 20.5)
            img, ratio, pad = letterbox(img, shape, auto=False, scaleup=self.augment)
            shapes = (h0, w0), ((h / h0, w / w0), pad)  # for COCO mAP rescaling
            # å›¾ç‰‡letterboxä¹‹ålabelçš„åæ ‡ä¹Ÿè¦ç›¸åº”å˜åŒ–  æ ¹æ®padè°ƒæ•´labelåæ ‡ å¹¶å°†å½’ä¸€åŒ–çš„xywh -> æœªå½’ä¸€åŒ–çš„xyxy
            labels = self.labels[index].copy()
            if labels.size:  # normalized xywh to pixel xyxy format
                labels[:, 1:] = xywhn2xyxy(labels[:, 1:], ratio[0] * w, ratio[1] * h, padw=pad[0], padh=pad[1])

            shape2 = self.batch_shapes2[self.batch2[index]] if self.rect else self.img_size  # final letterboxed shape
            # 4.2 letterbox è¿™ä¸€æ­¥å°†ç¬¬ä¸€æ­¥ç¼©æ”¾å¾—åˆ°çš„å›¾ç‰‡å†ç¼©æ”¾åˆ°å½“å‰batchæ‰€éœ€è¦çš„å°ºåº¦
            # çŸ©å½¢æ¨ç†éœ€è¦ä¸€ä¸ªbatchçš„æ‰€æœ‰å›¾ç‰‡çš„shapeå¿…é¡»ç›¸åŒ
            # è¿™é‡Œæ²¡æœ‰ç¼©æ”¾æ“ä½œï¼Œæ‰€ä»¥è¿™é‡Œçš„ratioæ°¸è¿œéƒ½æ˜¯(1.0, 1.0)  pad=(0.0, 20.5)
            img2, ratio2, pad2 = letterbox(img2, shape2, auto=False, scaleup=self.augment)
            shapes2 = (h02, w02), ((h2 / h02, w2 / w02), pad2)  # for COCO mAP rescaling
            # å›¾ç‰‡letterboxä¹‹ålabelçš„åæ ‡ä¹Ÿè¦ç›¸åº”å˜åŒ–  æ ¹æ®padè°ƒæ•´labelåæ ‡ å¹¶å°†å½’ä¸€åŒ–çš„xywh -> æœªå½’ä¸€åŒ–çš„xyxy
            labels2 = self.labels2[index].copy()
            if labels2.size:  # normalized xywh to pixel xyxy format
                labels2[:, 1:] = xywhn2xyxy(labels2[:, 1:], ratio2[0] * w2, ratio2[1] * h2, padw=pad2[0], padh=pad2[1])

            if self.augment:
                # 5ã€random_perspectiveå¢å¼º: éšæœºå¯¹å›¾ç‰‡è¿›è¡Œæ—‹è½¬ï¼Œå¹³ç§»ï¼Œç¼©æ”¾ï¼Œè£å‰ªï¼Œé€è§†å˜æ¢
                img, img2, labels = random_perspective(img, img2,
                                                       labels,
                                                       degrees=hyp['degrees'],
                                                       translate=hyp['translate'],
                                                       scale=hyp['scale'],
                                                       shear=hyp['shear'],
                                                       perspective=hyp['perspective'])
        # labelsçš„æ•°é‡
        nl = len(labels)  # number of labels
        if nl:  # è‹¥ä¸ä¸º0
            # è½¬æ¢Labelå°ºå¯¸ä¸ªæ•° å°†æœªå½’ä¸€åŒ–çš„xyxy ->å½’ä¸€åŒ–çš„xywz
            labels[:, 1:5] = xyxy2xywhn(labels[:, 1:5], w=img.shape[1], h=img.shape[0], clip=True, eps=1E-3)

        if self.augment:
            # Albumentations
            img, img2, labels = self.albumentations(img, img2, labels)
            nl = len(labels)  # update after albumentations

            # HSV color-spaceï¼ˆhsvè‰²åŸŸç©ºé—´å¢å¼ºï¼‰
            augment_hsv(img, hgain=hyp['hsv_h'], sgain=hyp['hsv_s'], vgain=hyp['hsv_v'])
            augment_hsv(img2, hgain=hyp['hsv_h'], sgain=hyp['hsv_s'], vgain=hyp['hsv_v'])
            # Flip up-downï¼ˆéšæœºä¸Šæ—‹ç¿»è½¬ï¼‰
            if random.random() < hyp['flipud']:
                img = np.flipud(img)
                img2 = np.flipud(img2)
                if nl:
                    labels[:, 2] = 1 - labels[:, 2]

            # Flip left-rightï¼ˆéšæœºå·¦å³ç¿»è½¬ï¼‰
            if random.random() < hyp['fliplr']:
                img = np.fliplr(img)
                img2 = np.fliplr(img2)
                if nl:
                    labels[:, 1] = 1 - labels[:, 1]

            # Cutouts
            # labels = cutout(img, labels, p=0.5)
            # nl = len(labels)  # update after cutout
        # åˆå§‹åŒ–æ ‡ç­¾æ¡†å¯¹åº”çš„å›¾ç‰‡åºå·ï¼Œé…åˆä¸‹é¢çš„collate_fnä½¿ç”¨
        labels_out = torch.zeros((nl, 6))
        if nl:
            labels_out[:, 1:] = torch.from_numpy(labels)

        # Convert
        img = img.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGBï¼ˆå›¾åƒBGRè½¬å˜æˆRGBï¼‰
        img2 = img2.transpose((2, 0, 1))[::-1]
        img = np.ascontiguousarray(img)  # åŠ å¿«è¿ç®—
        img2 = np.ascontiguousarray(img2)  # åŠ å¿«è¿ç®—
        return torch.from_numpy(img), torch.from_numpy(img2), labels_out, self.im_files[index], self.im_files2[
            index], shapes, shapes2

    """   
    è¿”å›å€¼ï¼š
    1ã€torch.from_numpy(img): è¿™ä¸ªindexçš„å›¾ç‰‡æ•°æ®(å¢å¼ºå) [3, 640, 640]
    2ã€labels_out: è¿™ä¸ªindexå›¾ç‰‡çš„gt label [6, 6] = [gt_num, 0+class+xywh(normalized)]
    3ã€self.img_files[index]: è¿™ä¸ªindexå›¾ç‰‡çš„è·¯å¾„åœ°å€
    4ã€shapes: è¿™ä¸ªbatchçš„å›¾ç‰‡çš„shapes æµ‹è¯•æ—¶(çŸ©å½¢è®­ç»ƒ)æ‰æœ‰  éªŒè¯æ—¶ä¸ºNone
    """

    # å·²ä¿®æ”¹
    def load_image(self, i):
        # Loads 1 image from dataset index 'i', returns (im, original hw, resized hw)
        im, f, fn = self.ims[i], self.im_files[i], self.npy_files[i],
        if im is None:  # not cached in RAM
            if fn.exists():  # load npy
                im = np.load(fn)
            else:  # read image
                im = cv2.imread(f)  # BGR
                assert im is not None, f'Image Not Found {f}'
            h0, w0 = im.shape[:2]  # orig hw
            r = self.img_size / max(h0, w0)  # ratio
            if r != 1:  # if sizes are not equal
                interp = cv2.INTER_LINEAR if (self.augment or r > 1) else cv2.INTER_AREA
                im = cv2.resize(im, (math.ceil(w0 * r), math.ceil(h0 * r)), interpolation=interp)
            return im, (h0, w0), im.shape[:2]  # im, hw_original, hw_resized
        return self.ims[i], self.im_hw0[i], self.im_hw[i]  # im, hw_original, hw_resized

    """è¿”å›ä¸ºå›¾åƒï¼ŒåŸå§‹å›¾åƒhwï¼Œresizeä¹‹åå›¾åƒhw"""

    # å·²ä¿®æ”¹ï¼ˆä¸»è¦ä¿®æ”¹å›¾åƒã€å›¾åƒè·¯å¾„ã€npyå›¾åƒè·¯å¾„ï¼‰å¦‚æœæ²¡æœ‰è¯¥å›¾åƒï¼Œåˆ™æ‰“å°è¯¥å›¾åƒæ–‡ä»¶æ²¡æœ‰è¢«å‘ç°
    def load_image2(self, i):
        # Loads 1 image from dataset index 'i', returns (im, original hw, resized hw)
        im, f, fn = self.ims2[i], self.im_files2[i], self.npy_files2[i],
        if im is None:  # not cached in RAM
            if fn.exists():  # load npy
                im = np.load(fn)
            else:  # read image
                im = cv2.imread(f)  # BGR
                assert im is not None, f'Image Not Found {f}'
            h0, w0 = im.shape[:2]  # orig hw
            r = self.img_size / max(h0, w0)  # ratio
            if r != 1:  # if sizes are not equal
                interp = cv2.INTER_LINEAR if (self.augment or r > 1) else cv2.INTER_AREA
                im = cv2.resize(im, (math.ceil(w0 * r), math.ceil(h0 * r)), interpolation=interp)
            return im, (h0, w0), im.shape[:2]  # im, hw_original, hw_resized
        return self.ims[i], self.im_hw0[i], self.im_hw[i]  # im, hw_original, hw_resized

    # """è¿”å›ä¸ºå›¾åƒï¼ŒåŸå§‹å›¾åƒhwï¼Œresizeä¹‹åå›¾åƒhw"""
    # def cache_images_to_disk(self, i):
    #     # Saves an image as an *.npy file for faster loading
    #     # å°†å›¾åƒå¦å­˜ä¸º *.npy æ–‡ä»¶ä»¥åŠ å¿«åŠ è½½é€Ÿåº¦
    #     f = self.npy_files[i]
    #     if not f.exists():
    #         np.save(f.as_posix(), cv2.imread(self.im_files[i]))

    # å·²ä¿®æ”¹ï¼ˆæ‹¼æ¥ã€é©¬èµ›å…‹ç­‰ç­‰æ•°æ®å¢å¼ºï¼‰
    def load_mosaic(self, index):  # selfè‡ªå®šä¹‰æ•°æ®é›† indexè¦å¢å¼ºçš„ç´¢å¼•
        # YOLOv5 4-mosaic loader. Loads 1 image + 3 random images into a 4-image mosaic
        labels4, segments4 = [], []
        s = self.img_size
        # éšæœºé€‰å–ä¸€ä¸ªä¸­å¿ƒç‚¹
        yc, xc = (int(random.uniform(-x, 2 * s + x)) for x in self.mosaic_border)  # mosaic center x, y
        indices = [index] + random.choices(self.indices, k=3)  # 3 additional image indices
        # éšæœºå–å…¶ä»–ä¸‰å¼ å›¾ç‰‡ç´¢å¼•
        random.shuffle(indices)
        for i, index in enumerate(indices):
            # Load image
            img, _, (h, w) = self.load_image(index)  # load_image åŠ è½½å›¾ç‰‡æ ¹æ®è®¾å®šçš„è¾“å…¥å¤§å°ä¸å›¾ç‰‡åŸå¤§å°çš„æ¯”ä¾‹è¿›è¡Œresize
            img2, _, (h2, w2) = self.load_image2(index)  # load_image åŠ è½½å›¾ç‰‡æ ¹æ®è®¾å®šçš„è¾“å…¥å¤§å°ä¸å›¾ç‰‡åŸå¤§å°çš„æ¯”ä¾‹è¿›è¡Œresize

            # place img in img4
            if i == 0:  # top left
                # åˆå§‹åŒ–å¤§å›¾
                img4 = np.full((s * 2, s * 2, img.shape[2]), 114, dtype=np.uint8)  # base image with 4 tiles
                img42 = np.full((s * 2, s * 2, img2.shape[2]), 114, dtype=np.uint8)  # base image with 4 tiles
                # æŠŠåŸå›¾æ”¾åˆ°å·¦ä¸Šè§’
                x1a, y1a, x2a, y2a = max(xc - w, 0), max(yc - h, 0), xc, yc  # xmin, ymin, xmax, ymax (large image)
                # é€‰å–å°å›¾ä¸Šçš„ä½ç½® å¦‚æœå›¾ç‰‡è¶Šç•Œä¼šè£å‰ª
                x1b, y1b, x2b, y2b = w - (x2a - x1a), h - (y2a - y1a), w, h  # xmin, ymin, xmax, ymax (small image)
            elif i == 1:  # top right
                x1a, y1a, x2a, y2a = xc, max(yc - h, 0), min(xc + w, s * 2), yc
                x1b, y1b, x2b, y2b = 0, h - (y2a - y1a), min(w, x2a - x1a), h
            elif i == 2:  # bottom left
                x1a, y1a, x2a, y2a = max(xc - w, 0), yc, xc, min(s * 2, yc + h)
                x1b, y1b, x2b, y2b = w - (x2a - x1a), 0, w, min(y2a - y1a, h)
            elif i == 3:  # bottom right
                x1a, y1a, x2a, y2a = xc, yc, min(xc + w, s * 2), min(s * 2, yc + h)
                x1b, y1b, x2b, y2b = 0, 0, min(w, x2a - x1a), min(y2a - y1a, h)
            # å°å›¾ä¸Šæˆªå–çš„éƒ¨åˆ†è´´åˆ°å¤§å›¾ä¸Š
            img4[y1a:y2a, x1a:x2a] = img[y1b:y2b, x1b:x2b]  # img4[ymin:ymax, xmin:xmax]
            img42[y1a:y2a, x1a:x2a] = img2[y1b:y2b, x1b:x2b]  # img4[ymin:ymax, xmin:xmax]
            # è®¡ç®—å°å›¾åˆ°å¤§å›¾åçš„åç§» ç”¨æ¥ç¡®å®šç›®æ ‡æ¡†çš„ä½ç½®
            padw = x1a - x1b
            padh = y1a - y1b

            # Labels
            labels, segments = self.labels[index].copy(), self.segments[index].copy()
            # æ ‡ç­¾è£å‰ª
            if labels.size:
                labels[:, 1:] = xywhn2xyxy(labels[:, 1:], w, h, padw, padh)  # normalized xywh to pixel xyxy format
                segments = [xyn2xy(x, w, h, padw, padh) for x in segments]
            labels4.append(labels)  # å¾—åˆ°æ–°çš„labelçš„åæ ‡
            segments4.extend(segments)

        # Concat/clip labels
        labels4 = np.concatenate(labels4, 0)
        for x in (labels4[:, 1:], *segments4):
            np.clip(x, 0, 2 * s, out=x)  # clip when using random_perspective()
        # img4, labels4 = replicate(img4, labels4)  # replicate

        # Augment
        # å°†å›¾ç‰‡ä¸­æ²¡ç›®æ ‡çš„ å–åˆ«çš„å›¾è¿›è¡Œç²˜è´´
        img4, img42, labels4, segments4 = copy_paste(img4, img42, labels4, segments4, p=self.hyp['copy_paste'])
        # éšæœºå˜æ¢
        img4, img42, labels4 = random_perspective(img4, img42, labels4, segments4,
                                                  degrees=self.hyp['degrees'],
                                                  translate=self.hyp['translate'],
                                                  scale=self.hyp['scale'],
                                                  shear=self.hyp['shear'],
                                                  perspective=self.hyp['perspective'],
                                                  border=self.mosaic_border)  # border to remove

        return img4, img42, labels4  # è¿”å›æ•°æ®å¢å¼ºçš„åçš„å›¾ç‰‡å’Œæ ‡ç­¾

    # def load_mosaic(self, index):
    #     # YOLOv5 4-mosaic loader. Loads 1 image + 3 random images into a 4-image mosaic
    #     # YOLOv5 4 é©¬èµ›å…‹åŠ è½½å™¨ã€‚å°† 1 å¼ å›¾åƒ + 3 å¼ éšæœºå›¾åƒåŠ è½½åˆ° 4 å¼ å›¾åƒçš„é©¬èµ›å…‹ä¸­
    #     labels4, segments4 = [], []
    #     s = self.img_size
    #     yc, xc = (int(random.uniform(-x, 2 * s + x)) for x in self.mosaic_border)  # mosaic center x, y
    #     indices = [index] + random.choices(self.indices, k=3)  # 3 additional image indices
    #     random.shuffle(indices)
    #     for i, index in enumerate(indices):
    #         # Load image
    #         img, _, (h, w) = self.load_image(index)
    #
    #         # place img in img4
    #         if i == 0:  # top left
    #             img4 = np.full((s * 2, s * 2, img.shape[2]), 114, dtype=np.uint8)  # base image with 4 tiles
    #             x1a, y1a, x2a, y2a = max(xc - w, 0), max(yc - h, 0), xc, yc  # xmin, ymin, xmax, ymax (large image)
    #             x1b, y1b, x2b, y2b = w - (x2a - x1a), h - (y2a - y1a), w, h  # xmin, ymin, xmax, ymax (small image)
    #         elif i == 1:  # top right
    #             x1a, y1a, x2a, y2a = xc, max(yc - h, 0), min(xc + w, s * 2), yc
    #             x1b, y1b, x2b, y2b = 0, h - (y2a - y1a), min(w, x2a - x1a), h
    #         elif i == 2:  # bottom left
    #             x1a, y1a, x2a, y2a = max(xc - w, 0), yc, xc, min(s * 2, yc + h)
    #             x1b, y1b, x2b, y2b = w - (x2a - x1a), 0, w, min(y2a - y1a, h)
    #         elif i == 3:  # bottom right
    #             x1a, y1a, x2a, y2a = xc, yc, min(xc + w, s * 2), min(s * 2, yc + h)
    #             x1b, y1b, x2b, y2b = 0, 0, min(w, x2a - x1a), min(y2a - y1a, h)
    #
    #         img4[y1a:y2a, x1a:x2a] = img[y1b:y2b, x1b:x2b]  # img4[ymin:ymax, xmin:xmax]
    #         padw = x1a - x1b
    #         padh = y1a - y1b
    #
    #         # Labels
    #         labels, segments = self.labels[index].copy(), self.segments[index].copy()
    #         if labels.size:
    #             labels[:, 1:] = xywhn2xyxy(labels[:, 1:], w, h, padw, padh)  # normalized xywh to pixel xyxy format
    #             segments = [xyn2xy(x, w, h, padw, padh) for x in segments]
    #         labels4.append(labels)
    #         segments4.extend(segments)
    #
    #     # Concat/clip labels
    #     labels4 = np.concatenate(labels4, 0)
    #     for x in (labels4[:, 1:], *segments4):
    #         np.clip(x, 0, 2 * s, out=x)  # clip when using random_perspective()
    #     # img4, labels4 = replicate(img4, labels4)  # replicate
    #
    #     # Augment
    #     img4, labels4, segments4 = copy_paste(img4, labels4, segments4, p=self.hyp['copy_paste'])
    #     img4, labels4 = random_perspective(img4,
    #                                        labels4,
    #                                        segments4,
    #                                        degrees=self.hyp['degrees'],
    #                                        translate=self.hyp['translate'],
    #                                        scale=self.hyp['scale'],
    #                                        shear=self.hyp['shear'],
    #                                        perspective=self.hyp['perspective'],
    #                                        border=self.mosaic_border)  # border to remove
    #
    #     return img4, labels4

    # def load_mosaic9(self, index):
    #     # YOLOv5 9-mosaic loader. Loads 1 image + 8 random images into a 9-image mosaic
    #     # YOLOv5 9 é©¬èµ›å…‹åŠ è½½å™¨ã€‚å°† 1 å¼ å›¾åƒ + 8 å¼ éšæœºå›¾åƒåŠ è½½åˆ° 9 å¼ å›¾åƒçš„é©¬èµ›å…‹ä¸­
    #     labels9, segments9 = [], []
    #     s = self.img_size
    #     indices = [index] + random.choices(self.indices, k=8)  # 8 additional image indices
    #     random.shuffle(indices)
    #     hp, wp = -1, -1  # height, width previous
    #     for i, index in enumerate(indices):
    #         # Load image
    #         img, _, (h, w) = self.load_image(index)
    #
    #         # place img in img9
    #         if i == 0:  # center
    #             img9 = np.full((s * 3, s * 3, img.shape[2]), 114, dtype=np.uint8)  # base image with 4 tiles
    #             h0, w0 = h, w
    #             c = s, s, s + w, s + h  # xmin, ymin, xmax, ymax (base) coordinates
    #         elif i == 1:  # top
    #             c = s, s - h, s + w, s
    #         elif i == 2:  # top right
    #             c = s + wp, s - h, s + wp + w, s
    #         elif i == 3:  # right
    #             c = s + w0, s, s + w0 + w, s + h
    #         elif i == 4:  # bottom right
    #             c = s + w0, s + hp, s + w0 + w, s + hp + h
    #         elif i == 5:  # bottom
    #             c = s + w0 - w, s + h0, s + w0, s + h0 + h
    #         elif i == 6:  # bottom left
    #             c = s + w0 - wp - w, s + h0, s + w0 - wp, s + h0 + h
    #         elif i == 7:  # left
    #             c = s - w, s + h0 - h, s, s + h0
    #         elif i == 8:  # top left
    #             c = s - w, s + h0 - hp - h, s, s + h0 - hp
    #
    #         padx, pady = c[:2]
    #         x1, y1, x2, y2 = (max(x, 0) for x in c)  # allocate coords
    #
    #         # Labels
    #         labels, segments = self.labels[index].copy(), self.segments[index].copy()
    #         if labels.size:
    #             labels[:, 1:] = xywhn2xyxy(labels[:, 1:], w, h, padx, pady)  # normalized xywh to pixel xyxy format
    #             segments = [xyn2xy(x, w, h, padx, pady) for x in segments]
    #         labels9.append(labels)
    #         segments9.extend(segments)
    #
    #         # Image
    #         img9[y1:y2, x1:x2] = img[y1 - pady:, x1 - padx:]  # img9[ymin:ymax, xmin:xmax]
    #         hp, wp = h, w  # height, width previous
    #
    #     # Offset
    #     yc, xc = (int(random.uniform(0, s)) for _ in self.mosaic_border)  # mosaic center x, y
    #     img9 = img9[yc:yc + 2 * s, xc:xc + 2 * s]
    #
    #     # Concat/clip labels
    #     labels9 = np.concatenate(labels9, 0)
    #     labels9[:, [1, 3]] -= xc
    #     labels9[:, [2, 4]] -= yc
    #     c = np.array([xc, yc])  # centers
    #     segments9 = [x - c for x in segments9]
    #
    #     for x in (labels9[:, 1:], *segments9):
    #         np.clip(x, 0, 2 * s, out=x)  # clip when using random_perspective()
    #     # img9, labels9 = replicate(img9, labels9)  # replicate
    #
    #     # Augment
    #     img9, labels9, segments9 = copy_paste(img9, labels9, segments9, p=self.hyp['copy_paste'])
    #     img9, labels9 = random_perspective(img9,
    #                                        labels9,
    #                                        segments9,
    #                                        degrees=self.hyp['degrees'],
    #                                        translate=self.hyp['translate'],
    #                                        scale=self.hyp['scale'],
    #                                        shear=self.hyp['shear'],
    #                                        perspective=self.hyp['perspective'],
    #                                        border=self.mosaic_border)  # border to remove
    #
    #     return img9, labels9
    # å·²ä¿®æ”¹
    @staticmethod
    def collate_fn(batch):  # å¦‚ä½•å–æ ·æœ¬
        """
        æ•´ç†å‡½æ•°  å°†imageå’Œlabelæ•´åˆåˆ°ä¸€èµ·
        pytorchçš„DataLoaderæ‰“åŒ…ä¸€ä¸ªbatchçš„æ•°æ®é›†æ—¶è¦ç»è¿‡æ­¤å‡½æ•°è¿›è¡Œæ‰“åŒ… é€šè¿‡é‡å†™æ­¤å‡½æ•°å®ç°æ ‡ç­¾ä¸å›¾ç‰‡å¯¹åº”çš„åˆ’åˆ†ï¼Œ
        ä¸€ä¸ªbatchä¸­å“ªäº›æ ‡ç­¾å±äºå“ªä¸€å¼ å›¾ç‰‡,å½¢å¦‚
            [[0, 6, 0.5, 0.5, 0.26, 0.35],
             [0, 6, 0.5, 0.5, 0.26, 0.35],
             [1, 6, 0.5, 0.5, 0.26, 0.35],
             [2, 6, 0.5, 0.5, 0.26, 0.35],]
             å›¾ç‰‡ç¼–å·ã€labelsç±»åˆ«ç¼–å· xywh
        """
        # img: ä¸€ä¸ªtuple ç”±batch_sizeä¸ªtensorç»„æˆ æ•´ä¸ªbatchä¸­æ¯ä¸ªtensorè¡¨ç¤ºä¸€å¼ å›¾ç‰‡
        # label: ä¸€ä¸ªtuple ç”±batch_sizeä¸ªtensorç»„æˆ æ¯ä¸ªtensorå­˜æ”¾ä¸€å¼ å›¾ç‰‡çš„æ‰€æœ‰çš„targetä¿¡æ¯
        # label[6, object_num] 6ä¸­çš„ç¬¬ä¸€ä¸ªæ•°ä»£è¡¨ä¸€ä¸ªbatchä¸­çš„ç¬¬å‡ å¼ å›¾
        # path: ä¸€ä¸ªtuple ç”±4ä¸ªstrç»„æˆ, æ¯ä¸ªstrå¯¹åº”ä¸€å¼ å›¾ç‰‡çš„åœ°å€ä¿¡æ¯

        im, im2, label, path, path2, shapes, shape2 = zip(*batch)  # transposed
        for i, lb in enumerate(label):
            lb[:, 0] = i  # add target image index for build_targets()
        # torch.stack(img, 0): æ•´ä¸ªbatchçš„å›¾ç‰‡--numpy
        # torch.cat(label, 0): [num_target, img_index+class_index+xywh(normalized)] æ•´ä¸ªbatchçš„label
        # path: æ•´ä¸ªbatchæ‰€æœ‰å›¾ç‰‡çš„è·¯å¾„
        # shapes: (h0, w0), ((h / h0, w / w0), pad)
        return torch.stack(im, 0), torch.stack(im2, 0), torch.cat(label, 0), path, path2, shapes, shape2

    # å·²ä¿®æ”¹
    @staticmethod
    def collate_fn4(batch):
        """åŒæ ·åœ¨create_dataloaderä¸­ç”Ÿæˆdataloaderæ—¶è°ƒç”¨ï¼š
        è¿™é‡Œæ˜¯yolo-v5ä½œè€…å®éªŒæ€§çš„ä¸€ä¸ªä»£ç  quad-collate function å½“train.pyçš„optå‚æ•°quad=True åˆ™è°ƒç”¨collate_fn4ä»£æ›¿collate_fn
        ä½œç”¨:  å¦‚ä¹‹å‰ç”¨collate_fnå¯ä»¥è¿”å›å›¾ç‰‡[16, 3, 640, 640] ç»è¿‡collate_fn4åˆ™è¿”å›å›¾ç‰‡[4, 3, 1280, 1280]
              å°†4å¼ mosaicå›¾ç‰‡[1, 3, 640, 640]åˆæˆä¸€å¼ å¤§çš„mosaicå›¾ç‰‡[1, 3, 1280, 1280]
              å°†ä¸€ä¸ªbatchçš„å›¾ç‰‡æ¯å››å¼ å¤„ç†, 0.5çš„æ¦‚ç‡å°†å››å¼ å›¾ç‰‡æ‹¼æ¥åˆ°ä¸€å¼ å¤§å›¾ä¸Šè®­ç»ƒ, 0.5æ¦‚ç‡ç›´æ¥å°†æŸå¼ å›¾ç‰‡ä¸Šé‡‡æ ·ä¸¤å€è®­ç»ƒ
        """
        im, im2, label, path, path2, shapes, shapes2 = zip(*batch)  # transposed
        n = len(shapes) // 4
        im4, im42, label4, path4, path42, shapes4, shapes42 = [], [], [], path[:n], path[:n2], shapes[:n], shapes[:n2]

        ho = torch.tensor([[0.0, 0, 0, 1, 0, 0]])
        wo = torch.tensor([[0.0, 0, 1, 0, 0, 0]])
        s = torch.tensor([[1, 1, 0.5, 0.5, 0.5, 0.5]])  # scale
        for i in range(n):  # zidane torch.zeros(16,3,720,1280)  # BCHW
            i *= 4
            if random.random() < 0.5:
                im1 = F.interpolate(im[i].unsqueeze(0).float(), scale_factor=2.0, mode='bilinear',
                                    align_corners=False)[0].type(im[i].type())

                im2 = F.interpolate(im2[i].unsqueeze(0).float(), scale_factor=2.0, mode='bilinear',
                                    align_corners=False)[0].type(im2[i].type())
                lb = label[i]
            else:
                im1 = torch.cat((torch.cat((im[i], im[i + 1]), 1), torch.cat((im[i + 2], im[i + 3]), 1)), 2)
                im2 = torch.cat((torch.cat((im2[i], im2[i + 1]), 1), torch.cat((im2[i + 2], im2[i + 3]), 1)), 2)
                lb = torch.cat((label[i], label[i + 1] + ho, label[i + 2] + wo, label[i + 3] + ho + wo), 0) * s
            im4.append(im1)
            im42.append(im2)
            label4.append(lb)

        for i, lb in enumerate(label4):
            lb[:, 0] = i  # add target image index for build_targets()

        return torch.stack(im4, 0), torch.stack(im42, 0), torch.cat(label4, 0), path4, path42, shapes4, shapes42


# Ancillary functions --------------------------------------------------------------------------------------------------
def flatten_recursive(path=DATASETS_DIR / 'coco128'):
    # Flatten a recursive directory by bringing all files to top level
    new_path = Path(f'{str(path)}_flat')
    if os.path.exists(new_path):
        shutil.rmtree(new_path)  # delete output folder
    os.makedirs(new_path)  # make new output folder
    for file in tqdm(glob.glob(f'{str(Path(path))}/**/*.*', recursive=True)):
        shutil.copyfile(file, new_path / Path(file).name)


def extract_boxes(path=DATASETS_DIR / 'coco128'):  # from utils.dataloaders import *; extract_boxes()
    # Convert detection dataset into classification dataset, with one directory per class
    path = Path(path)  # images dir
    shutil.rmtree(path / 'classification') if (path / 'classification').is_dir() else None  # remove existing
    files = list(path.rglob('*.*'))
    n = len(files)  # number of files
    for im_file in tqdm(files, total=n):
        if im_file.suffix[1:] in IMG_FORMATS:
            # image
            im = cv2.imread(str(im_file))[..., ::-1]  # BGR to RGB
            h, w = im.shape[:2]

            # labels
            lb_file = Path(img2label_paths([str(im_file)])[0])
            if Path(lb_file).exists():
                with open(lb_file) as f:
                    lb = np.array([x.split() for x in f.read().strip().splitlines()], dtype=np.float32)  # labels

                for j, x in enumerate(lb):
                    c = int(x[0])  # class
                    f = (path / 'classifier') / f'{c}' / f'{path.stem}_{im_file.stem}_{j}.jpg'  # new filename
                    if not f.parent.is_dir():
                        f.parent.mkdir(parents=True)

                    b = x[1:] * [w, h, w, h]  # box
                    # b[2:] = b[2:].max()  # rectangle to square
                    b[2:] = b[2:] * 1.2 + 3  # pad
                    b = xywh2xyxy(b.reshape(-1, 4)).ravel().astype(int)

                    b[[0, 2]] = np.clip(b[[0, 2]], 0, w)  # clip boxes outside of image
                    b[[1, 3]] = np.clip(b[[1, 3]], 0, h)
                    assert cv2.imwrite(str(f), im[b[1]:b[3], b[0]:b[2]]), f'box failure in {f}'


def autosplit(path=DATASETS_DIR / 'coco128/images', weights=(0.9, 0.1, 0.0), annotated_only=False):
    """ Autosplit a dataset into train/val/test splits and save path/autosplit_*.txt files
    Usage: from utils.dataloaders import *; autosplit()
    Arguments
        path:            Path to images directory
        weights:         Train, val, test weights (list, tuple)
        annotated_only:  Only use images with an annotated txt file
    """
    path = Path(path)  # images dir
    files = sorted(x for x in path.rglob('*.*') if x.suffix[1:].lower() in IMG_FORMATS)  # image files only
    n = len(files)  # number of files
    random.seed(0)  # for reproducibility
    indices = random.choices([0, 1, 2], weights=weights, k=n)  # assign each image to a split

    txt = ['autosplit_train.txt', 'autosplit_val.txt', 'autosplit_test.txt']  # 3 txt files
    for x in txt:
        if (path.parent / x).exists():
            (path.parent / x).unlink()  # remove existing

    print(f'Autosplitting images from {path}' + ', using *.txt labeled images only' * annotated_only)
    for i, img in tqdm(zip(indices, files), total=n):
        if not annotated_only or Path(img2label_paths([str(img)])[0]).exists():  # check label
            with open(path.parent / txt[i], 'a') as f:
                f.write(f'./{img.relative_to(path.parent).as_posix()}' + '\n')  # add image to txt file


def verify_image_label(args):
    # Verify one image-label pair
    im_file, lb_file, prefix = args
    nm, nf, ne, nc, msg, segments = 0, 0, 0, 0, '', []  # number (missing, found, empty, corrupt), message, segments
    try:
        # verify images
        im = Image.open(im_file)
        im.verify()  # PIL verify
        shape = exif_size(im)  # image size
        assert (shape[0] > 9) & (shape[1] > 9), f'image size {shape} <10 pixels'
        assert im.format.lower() in IMG_FORMATS, f'invalid image format {im.format}'
        if im.format.lower() in ('jpg', 'jpeg'):
            with open(im_file, 'rb') as f:
                f.seek(-2, 2)
                if f.read() != b'\xff\xd9':  # corrupt JPEG
                    ImageOps.exif_transpose(Image.open(im_file)).save(im_file, 'JPEG', subsampling=0, quality=100)
                    msg = f'{prefix}WARNING âš ï¸ {im_file}: corrupt JPEG restored and saved'

        # verify labels
        if os.path.isfile(lb_file):
            nf = 1  # label found
            with open(lb_file) as f:
                lb = [x.split() for x in f.read().strip().splitlines() if len(x)]
                if any(len(x) > 6 for x in lb):  # is segment
                    classes = np.array([x[0] for x in lb], dtype=np.float32)
                    segments = [np.array(x[1:], dtype=np.float32).reshape(-1, 2) for x in lb]  # (cls, xy1...)
                    lb = np.concatenate((classes.reshape(-1, 1), segments2boxes(segments)), 1)  # (cls, xywh)
                lb = np.array(lb, dtype=np.float32)
            nl = len(lb)
            if nl:
                assert lb.shape[1] == 5, f'labels require 5 columns, {lb.shape[1]} columns detected'
                assert (lb >= 0).all(), f'negative label values {lb[lb < 0]}'
                assert (lb[:, 1:] <= 1).all(), f'non-normalized or out of bounds coordinates {lb[:, 1:][lb[:, 1:] > 1]}'
                _, i = np.unique(lb, axis=0, return_index=True)
                if len(i) < nl:  # duplicate row check
                    lb = lb[i]  # remove duplicates
                    if segments:
                        segments = [segments[x] for x in i]
                    msg = f'{prefix}WARNING âš ï¸ {im_file}: {nl - len(i)} duplicate labels removed'
            else:
                ne = 1  # label empty
                lb = np.zeros((0, 5), dtype=np.float32)
        else:
            nm = 1  # label missing
            lb = np.zeros((0, 5), dtype=np.float32)
        return im_file, lb, shape, segments, nm, nf, ne, nc, msg
    except Exception as e:
        nc = 1
        msg = f'{prefix}WARNING âš ï¸ {im_file}: ignoring corrupt image/label: {e}'
        return [None, None, None, None, nm, nf, ne, nc, msg]


class HUBDatasetStats():
    """ Class for generating HUB dataset JSON and `-hub` dataset directory

    Arguments
        path:           Path to data.yaml or data.zip (with data.yaml inside data.zip)
        autodownload:   Attempt to download dataset if not found locally

    Usage
        from utils.dataloaders import HUBDatasetStats
        stats = HUBDatasetStats('coco128.yaml', autodownload=True)  # usage 1
        stats = HUBDatasetStats('path/to/coco128.zip')  # usage 2
        stats.get_json(save=False)
        stats.process_images()
    """

    def __init__(self, path='coco128.yaml', autodownload=False):
        # Initialize class
        zipped, data_dir, yaml_path = self._unzip(Path(path))
        try:
            with open(check_yaml(yaml_path), errors='ignore') as f:
                data = yaml.safe_load(f)  # data dict
                if zipped:
                    data['path'] = data_dir
        except Exception as e:
            raise Exception('error/HUB/dataset_stats/yaml_load') from e

        check_dataset(data, autodownload)  # download dataset if missing
        self.hub_dir = Path(data['path'] + '-hub')
        self.im_dir = self.hub_dir / 'images'
        self.im_dir.mkdir(parents=True, exist_ok=True)  # makes /images
        self.stats = {'nc': data['nc'], 'names': list(data['names'].values())}  # statistics dictionary
        self.data = data

    @staticmethod
    def _find_yaml(dir):
        # Return data.yaml file
        files = list(dir.glob('*.yaml')) or list(dir.rglob('*.yaml'))  # try root level first and then recursive
        assert files, f'No *.yaml file found in {dir}'
        if len(files) > 1:
            files = [f for f in files if f.stem == dir.stem]  # prefer *.yaml files that match dir name
            assert files, f'Multiple *.yaml files found in {dir}, only 1 *.yaml file allowed'
        assert len(files) == 1, f'Multiple *.yaml files found: {files}, only 1 *.yaml file allowed in {dir}'
        return files[0]

    def _unzip(self, path):
        # Unzip data.zip
        if not str(path).endswith('.zip'):  # path is data.yaml
            return False, None, path
        assert Path(path).is_file(), f'Error unzipping {path}, file not found'
        unzip_file(path, path=path.parent)
        dir = path.with_suffix('')  # dataset directory == zip name
        assert dir.is_dir(), f'Error unzipping {path}, {dir} not found. path/to/abc.zip MUST unzip to path/to/abc/'
        return True, str(dir), self._find_yaml(dir)  # zipped, data_dir, yaml_path

    def _hub_ops(self, f, max_dim=1920):
        # HUB ops for 1 image 'f': resize and save at reduced quality in /dataset-hub for web/app viewing
        f_new = self.im_dir / Path(f).name  # dataset-hub image filename
        try:  # use PIL
            im = Image.open(f)
            r = max_dim / max(im.height, im.width)  # ratio
            if r < 1.0:  # image too large
                im = im.resize((int(im.width * r), int(im.height * r)))
            im.save(f_new, 'JPEG', quality=50, optimize=True)  # save
        except Exception as e:  # use OpenCV
            LOGGER.info(f'WARNING âš ï¸ HUB ops PIL failure {f}: {e}')
            im = cv2.imread(f)
            im_height, im_width = im.shape[:2]
            r = max_dim / max(im_height, im_width)  # ratio
            if r < 1.0:  # image too large
                im = cv2.resize(im, (int(im_width * r), int(im_height * r)), interpolation=cv2.INTER_AREA)
            cv2.imwrite(str(f_new), im)

    def get_json(self, save=False, verbose=False):
        # Return dataset JSON for Ultralytics HUB
        def _round(labels):
            # Update labels to integer class and 6 decimal place floats
            return [[int(c), *(round(x, 4) for x in points)] for c, *points in labels]

        for split in 'train', 'val', 'test':
            if self.data.get(split) is None:
                self.stats[split] = None  # i.e. no test set
                continue
            dataset = LoadImagesAndLabels(self.data[split])  # load dataset
            x = np.array([
                np.bincount(label[:, 0].astype(int), minlength=self.data['nc'])
                for label in tqdm(dataset.labels, total=dataset.n, desc='Statistics')])  # shape(128x80)
            self.stats[split] = {
                'instance_stats': {
                    'total': int(x.sum()),
                    'per_class': x.sum(0).tolist()},
                'image_stats': {
                    'total': dataset.n,
                    'unlabelled': int(np.all(x == 0, 1).sum()),
                    'per_class': (x > 0).sum(0).tolist()},
                'labels': [{
                    str(Path(k).name): _round(v.tolist())} for k, v in zip(dataset.im_files, dataset.labels)]}

        # Save, print and return
        if save:
            stats_path = self.hub_dir / 'stats.json'
            print(f'Saving {stats_path.resolve()}...')
            with open(stats_path, 'w') as f:
                json.dump(self.stats, f)  # save stats.json
        if verbose:
            print(json.dumps(self.stats, indent=2, sort_keys=False))
        return self.stats

    def process_images(self):
        # Compress images for Ultralytics HUB
        for split in 'train', 'val', 'test':
            if self.data.get(split) is None:
                continue
            dataset = LoadImagesAndLabels(self.data[split])  # load dataset
            desc = f'{split} images'
            for _ in tqdm(ThreadPool(NUM_THREADS).imap(self._hub_ops, dataset.im_files), total=dataset.n, desc=desc):
                pass
        print(f'Done. All images saved to {self.im_dir}')
        return self.im_dir


# Classification dataloaders -------------------------------------------------------------------------------------------
class ClassificationDataset(torchvision.datasets.ImageFolder):
    """
    YOLOv5 Classification Dataset.
    Arguments
        root:  Dataset path
        transform:  torchvision transforms, used by default
        album_transform: Albumentations transforms, used if installed
    """

    def __init__(self, root, augment, imgsz, cache=False):
        super().__init__(root=root)
        self.torch_transforms = classify_transforms(imgsz)
        self.album_transforms = classify_albumentations(augment, imgsz) if augment else None
        self.cache_ram = cache is True or cache == 'ram'
        self.cache_disk = cache == 'disk'
        self.samples = [list(x) + [Path(x[0]).with_suffix('.npy'), None] for x in self.samples]  # file, index, npy, im

    def __getitem__(self, i):
        f, j, fn, im = self.samples[i]  # filename, index, filename.with_suffix('.npy'), image
        if self.cache_ram and im is None:
            im = self.samples[i][3] = cv2.imread(f)
        elif self.cache_disk:
            if not fn.exists():  # load npy
                np.save(fn.as_posix(), cv2.imread(f))
            im = np.load(fn)
        else:  # read image
            im = cv2.imread(f)  # BGR
        if self.album_transforms:
            sample = self.album_transforms(image=cv2.cvtColor(im, cv2.COLOR_BGR2RGB))['image']
        else:
            sample = self.torch_transforms(im)
        return sample, j


def create_classification_dataloader(path,
                                     imgsz=224,
                                     batch_size=16,
                                     augment=True,
                                     cache=False,
                                     rank=-1,
                                     workers=8,
                                     shuffle=True):
    # Returns Dataloader object to be used with YOLOv5 Classifier
    with torch_distributed_zero_first(rank):  # init dataset *.cache only once if DDP
        dataset = ClassificationDataset(root=path, imgsz=imgsz, augment=augment, cache=cache)
    batch_size = min(batch_size, len(dataset))
    nd = torch.cuda.device_count()
    nw = min([os.cpu_count() // max(nd, 1), batch_size if batch_size > 1 else 0, workers])
    sampler = None if rank == -1 else distributed.DistributedSampler(dataset, shuffle=shuffle)
    generator = torch.Generator()
    generator.manual_seed(6148914691236517205 + RANK)
    return InfiniteDataLoader(dataset,
                              batch_size=batch_size,
                              shuffle=shuffle and sampler is None,
                              num_workers=nw,
                              sampler=sampler,
                              pin_memory=PIN_MEMORY,
                              worker_init_fn=seed_worker,
                              generator=generator)  # or DataLoader(persistent_workers=True)
